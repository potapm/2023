{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962807c1-4b4a-4cdc-a769-a8cf3c34f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt install libgtk2.0-dev pkg-config -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd555978-0a3e-44f0-84cc-14a67a376aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eaa63c-ef0f-47bd-94f3-27cf6dbcd9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59736113-c2ed-419b-a466-0913e4726f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the video file\n",
    "video_path = \"./data3/KRA-44-168-2023-08-30-morning.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e18489-46be-4336-81af-a1db770f8e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4354d68-ea32-4c1d-98d2-4371e015e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 truck, 14.6ms\n",
      "Speed: 3.2ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 15.3ms\n",
      "Speed: 4.9ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Get the boxes and track IDs\u001b[39;00m\n\u001b[1;32m     26\u001b[0m boxes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxywh\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m---> 27\u001b[0m track_ids \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Visualize the results on the frame\u001b[39;00m\n\u001b[1;32m     30\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "# get video dims\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('./video9.mp4', fourcc, 20.0, size)\n",
    "\n",
    "\n",
    "count=1\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "    count += 11 # i.e. at 30 fps, this advances one second\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True)\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Plot the tracks\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))  # x, y center point\n",
    "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
    "                track.pop(0)\n",
    "\n",
    "            # Draw the tracking lines\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "            \n",
    "        out.write(annotated_frame)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f451689-24ae-4c7c-a1ca-731ddd2469c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a246a8-ba9c-4b47-8984-22443ad16897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
